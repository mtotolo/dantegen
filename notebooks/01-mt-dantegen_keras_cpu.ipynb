{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DanteGen: a tercet generator\n",
    "\n",
    "The purpose of this project is to create a generative model based on Dante's Divine Comdey loosely based on what A. Karpathy [did](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) with Shakespeare's works.\n",
    "I'm going to follow step by step what J. Howard [did](https://github.com/fastai/courses/blob/master/deeplearning1/nbs/char-rnn.ipynb) in one of his great lessons on fast.ai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\n",
    "from keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from numpy.random import random, permutation, randn, normal, uniform, choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by getting the text from Project Guttenberg at the link below and strip the header and footer.\n",
    "\n",
    "The whole text is converted to lowercase to reduce the overall dictionary length. It would be more interesting to keep the upper case characters and see if the model can correctly employ them. We also convert vowels with umlaut (ä, ë, ...) to unaccented vowels, for the same reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/Users/marcototolo/Projects/dantegen/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = get_file(PATH + 'data/raw/divcomm.txt', origin=\"http://www.gutenberg.org/files/1012/1012-0.txt\")\n",
    "text = open(fpath,encoding='utf8').read().lower()\n",
    "text = text[932:-19658]\n",
    "#umlaut = {'ä':'a','ë':'e','ï':'i','ö':'o','ü':'u','-':'—'}\n",
    "#for word, initial in umlaut.items():\n",
    "#    text = text.replace(word, initial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the beginning and end of the corpus, as well as the total length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la divina commedia\n",
      "  di dante alighieri\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  inferno\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  inferno • canto i\n",
      "\n",
      "\n",
      "  nel mezzo del cammin di nostra vita\n",
      "  mi ritrovai per una selva oscura,\n",
      "  ché la diritta via era smarrita.\n",
      "\n",
      "  ahi quanto a dir qual era è cosa dura\n",
      "  esta selva selvaggia e aspra e forte\n",
      "  che nel pensier rinova la paura!\n",
      "\n",
      "  tant’ è amara che poco è più morte;\n",
      "  ma per trattar del ben ch’i’ vi trovai,\n",
      "  dirò de l’altre cose ch’i’ v’ho scorte.\n",
      "\n",
      "  io non so ben ridir com’ i’ v’intrai,\n",
      "  tant’ era pien di sonno a que\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mètra che tutto s’affige\n",
      "  per misurar lo cerchio, e non ritrova,\n",
      "  pensando, quel principio ond’ elli indige,\n",
      "\n",
      "  tal era io a quella vista nova:\n",
      "  veder voleva come si convenne\n",
      "  l’imago al cerchio e come vi s’indova;\n",
      "\n",
      "  ma non eran da ciò le proprie penne:\n",
      "  se non che la mia mente fu percossa\n",
      "  da un fulgore in che sua voglia venne.\n",
      "\n",
      "  a l’alta fantasia qui mancò possa;\n",
      "  ma già volgeva il mio disio e ’l velle,\n",
      "  sì come rota ch’igualmente è mossa,\n",
      "\n",
      "  l’amor che move il sole e l’altre stelle.\n"
     ]
    }
   ],
   "source": [
    "print(text[-500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561094"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get the set of all characters in the text and print them out. We'll add a null carachter for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "chars.insert(0, \"\\0\")\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00\\n !(),-.:;?abcdefghijlmnopqrstuvxyz«»àäèéëìïòóöùü—‘’“”•'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to assign an index to each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now idx contains the whole divine comedy text encoded with the indeces we've just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 12, 2, 15, 20, 32, 20, 24, 12, 2, 14, 25, 23, 23, 16, 15, 20, 12]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:18] # = \"LA DIVINA COMMEDIA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la divina commedia\n"
     ]
    }
   ],
   "source": [
    "print(''.join(indices_char[i] for i in idx[:18]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will take the first n characters and try to predict the next one. Let's take n=40.\n",
    "\n",
    "We'll create all the 40 chars sequences in the text (sentences) and associate them to the 1-char shifted corresponding sequence (next_chars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 561055\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(idx) - maxlen+1):\n",
    "    sentences.append(idx[i: i + maxlen])\n",
    "    next_chars.append(idx[i+1: i+maxlen+1])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we cast them in np arrays and throw away the very last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((561053, 40), (561053, 40))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.shape, next_chars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fac = 24 #number of embeddings\n",
    "batch_size = 64\n",
    "LSTM_units = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define our model: we start with an embedding layer, followed by two LSTM networks and a fully connected layer with softmax to obtain each character probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=maxlen),\n",
    "        LSTM(LSTM_units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, \n",
    "             implementation=2),\n",
    "        Dropout(0.2),\n",
    "        LSTM(LSTM_units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, \n",
    "             implementation=2),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 40, 24)            1344      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 40, 512)           1099776   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 40, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 40, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 40, 512)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 40, 56)            28728     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 40, 56)            0         \n",
      "=================================================================\n",
      "Total params: 3,229,048\n",
      "Trainable params: 3,229,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a function to print an example of text generated from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(n=500, seed_string=\"nel mezzo del cammin di nostra vita\\n  mi\"):\n",
    "    for i in range(n):\n",
    "        x=np.array([char_indices[c] for c in seed_string[-maxlen:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(chars, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    print(seed_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "561053/561053 [==============================] - 14808s - loss: 1.5459 \n",
      "Epoch 2/2\n",
      "561053/561053 [==============================] - 14826s - loss: 1.3143 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1429dccf8>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('dante1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../models/dantegen_01_keras_cpu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nel mezzo del cammin di nostra vita\n",
      "  mi scende, né color non tenea far di quel giù battesmo.\n",
      "\n",
      "  «o al fangosto del lagrome femmine,\n",
      "\n",
      "  di qua tanto pur che li bassi levi.\n",
      "\n",
      "  e prima vorrà che tu riguardi\n",
      "  perché ’l tempo sono era e quel ch’i’ odo,\n",
      "  dove più mortali avea giovanni e ville,\n",
      "\n",
      "  sopra risposta il gelo a la virtù s’infrai.\n",
      "\n",
      "  di quel ch’è nel vero a questa spene,\n",
      "  se tu sorrisi e dinanzi tenea tutto ’l fine in su la poppa,\n",
      "  loda di grasde arco d’ubidiso ecquisto,\n",
      "  sì come abression là nostra volta qua degna;\n",
      "  ma ques\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might now make any sense unless you know some Italian, but you can see that the model correctly uses punctuation like full stops and question marks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "561053/561053 [==============================] - 14833s - loss: 1.2712 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x146eb3f98>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nel mezzo del cammin di nostra vita\n",
      "  mi facea le prime la suora d’amore,\n",
      "  onde per mostrarsi quïetato il sol percuote.\n",
      "\n",
      "  e vidi le labbra dentro a quel di grazia s’aia;\n",
      "  sola gente quale in paura si rincopra».\n",
      "\n",
      "  poi comincia’ io; ed elli a me: «l’anime salete?\n",
      "\n",
      "  com’ a la parola a la luce di gran sembiante,\n",
      "  montavano a la muffa e di là ond’ io scuso;\n",
      "  ma più el la faccia l’argomentar chiisa.\n",
      "\n",
      "  poscia vid’ io parea trïunfar lo martar del tuo dimando».\n",
      "\n",
      "  e io: «colui che mi parea tanto sì fatto,\n",
      "\n",
      "  e poi che son sterpi e tu d\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "561053/561053 [==============================] - 14884s - loss: 1.2482 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x146eb3be0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nel mezzo del cammin di nostra vita\n",
      "  mi fu correva la fronde piani,\n",
      "  ritrarrote a la parte onde si volgieno,\n",
      "  per viva unvider veder con porpo\n",
      "  scendere un poco a la tua conoscescia,\n",
      "  tratto ne l’aere antico e torto,\n",
      "  pur giù nel dir diedi ’l monte, da li alberti\n",
      "  voce se ne faran presso e margarita,\n",
      "  grida fortuna è colei che la ingama bolgia\n",
      "  si mosse, e falsai nel loco ove circunsto.\n",
      "\n",
      "  vinser li ambo le timi, e con saranno troia,\n",
      "  tanto dismontando, fu creato,\n",
      "  da estre, dopo la gente fansi,\n",
      "  e ora, e crescia i segni d\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "561053/561053 [==============================] - 19911s - loss: 1.2316 \n",
      "Epoch 2/3\n",
      "561053/561053 [==============================] - 14819s - loss: 1.2179 \n",
      "Epoch 3/3\n",
      "561053/561053 [==============================] - 15258s - loss: 1.2060 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x146eb3390>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nel mezzo del cammin di nostra vita\n",
      "  mi rimosse; e tutti suoi convene\n",
      "  fin questi verso le braccia aperse,\n",
      "  trovai d’altro secondo quento schiera,\n",
      "  poi disse: «ché noi a cui novelle sazio».\n",
      "\n",
      "  queste parole prieghe mar ch’a le mie porte\n",
      "  tutte raggia fiammelle, a veder ch’a bene star mie\n",
      "  quando si parrà di beccheria di mangia\n",
      "  dove pur l’ovra non sarebbe non si sponda.\n",
      "\n",
      "  or vien quella che merta richiude,\n",
      "  e non principio a chi lo sveglio in alcun sabo.\n",
      "\n",
      "  quand’ io avea poi d’una sete onde si ricorda,\n",
      "\n",
      "  come vel che la sen\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('dante1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nel mezzo del cammin di nostra vita\n",
      "  mi serva pria parlere, ad amar per nave,\n",
      "  solo a tante malizia fosser di piacenti,\n",
      "  prendere a veder, ché pur idïente acro\n",
      "  lo bulicame al mar si fu ammontibero.\n",
      "\n",
      "  lume ch’avrebber colto da le gran cima\n",
      "\n",
      "  di riguardar la barba in richiusa la creatura,\n",
      "  da l’armi», disse, «che siete voi?»,\n",
      "  diss’ io, «in sù hanno di là sù nel mondo,\n",
      "  lagrimando al fine ove si può sembiante;\n",
      "  e però l’atto d’amor m’era più vera,\n",
      "\n",
      "  anzi si stavan tanto spiriti giude,\n",
      "  disse: «come ii vidi già nel remo è sì\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nel mezzo del cammin di nostra vita\n",
      "  mi vide così si stozzasse\n",
      "  per tante stelle membra che la maria\n",
      "  sovr’ a cuuro e caldi la testa pianta,\n",
      "  prender le facelle del roman la coglia\n",
      "  che l’ali nasconde e corpo tutto fossi;\n",
      "\n",
      "  ed el sensibil cosa o dannata;\n",
      "  volsersi a noi poscia che ristetter li miei,\n",
      "  a bene arviver, facea male.\n",
      "\n",
      "  le membra più e più e per tre mlii,\n",
      "  odor che l’altro tanto non si scossa.\n",
      "\n",
      "  «o dolce poi di lor sapienza in sue figure scale;\n",
      "  avviso ancor non lasciava icinto e tarda,\n",
      "  ch’ardente da lucca a la sua mano a tutte quante.\n",
      "\n",
      "  e come a quel che sia la natura\n",
      "  che da lui le membra con le tue amor non rechera.\n",
      "\n",
      "  ombra v’eran colà, con pomi si siicchia.\n",
      "\n",
      "  lo vostro mondo sovra questo volto,\n",
      "  come ’l cerchio del cammin ci si specchia,\n",
      "  a dio verace di ciascuna reina,\n",
      "  che non soccorre assai è più lungo speranza,\n",
      "  come tempo ha del suo riguardar di questo,\n",
      "  dispuos’ io lui, «gridò: «fronda,\n",
      "  poro i piedi in lor felice,\n",
      "  poscia ch’elli ebbe chiuso, e io servente\n",
      "  le membra mie a verso\n"
     ]
    }
   ],
   "source": [
    "print_example(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training for a few more epochs, the results are interesting in terms of language used, but we still see a few mistakes: direct speech chunks are sometimes opened and not closed; the three line (tercet) pattern is mostly not used and the rhyming also doesn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a few combination of the model parameters and see if we can get some better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = [40,60]\n",
    "EMB = [24,32]\n",
    "LSTM_UNITS = [512,1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sequences(maxlen):\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(idx) - maxlen+1):\n",
    "        sentences.append(idx[i: i + maxlen])\n",
    "        next_chars.append(idx[i+1: i+maxlen+1])\n",
    "    sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "    next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])\n",
    "    return (sentences, next_chars)\n",
    "\n",
    "def get_model(maxlen, embeddings, LSTM_units):\n",
    "    model=Sequential([\n",
    "        Embedding(vocab_size, embeddings, input_length=maxlen),\n",
    "        LSTM(LSTM_units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, \n",
    "             implementation=2),\n",
    "        Dropout(0.2),\n",
    "        LSTM(LSTM_units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, \n",
    "             implementation=2),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import History\n",
    "k = 1\n",
    "losses = []\n",
    "for maxlen in MAX_LEN:\n",
    "    sentences, next_chars = get_sequences(maxlen)\n",
    "    for embeddings in EMB:\n",
    "        for units in LSTM_UNITS:\n",
    "            k = k + 1\n",
    "            model = get_model(maxlen, embeddings, units)\n",
    "            model.optimizer.lr = 0.01\n",
    "            history = History()\n",
    "            loss = 3\n",
    "            i = 0\n",
    "            while (loss>1.3) & (i<6):\n",
    "                i = i + 1\n",
    "                model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, epochs=1, \n",
    "                     callbacks=[history])\n",
    "                loss = history.history['loss'][-1]\n",
    "            print_example()\n",
    "            for j in [0.001,0.0001,0.00001,0.00001,0.00001]\n",
    "                model.optimizer.lr = j\n",
    "                model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, epochs=1, \n",
    "                     callbacks=[history])\n",
    "                print_example()\n",
    "            losses.append(history.history['loss'][-1])\n",
    "            model.save_weights('dante' + str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
